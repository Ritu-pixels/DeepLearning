{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Comparing_AlexNet_and_LeNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "n56DWbUB1OXG"
      },
      "source": [
        "  #Importing library\n",
        "  from keras.models import Sequential\n",
        "  from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, AvgPool2D\n",
        "  from keras.layers.normalization import BatchNormalization\n",
        "  import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyjKuMKgVC64"
      },
      "source": [
        "It's a small program of LeNet and AlexNet layers decriptions. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nif2PpygU1D9"
      },
      "source": [
        "LeNet_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6fbeE9wz8js"
      },
      "source": [
        "def lenet_model():\n",
        "  model = Sequential()\n",
        "  \n",
        "  # Must define the input shape in the first layer of the neural network\n",
        "  model.add(Conv2D(filters=6, kernel_size=5, activation='sigmoid',\n",
        "                               padding='same', input_shape=(28,28,1))) \n",
        "  model.add(AvgPool2D(pool_size=2, strides=2))\n",
        "  \n",
        "  model.add(Conv2D(filters=16, kernel_size=5,\n",
        "                               activation='sigmoid'))\n",
        "  model.add(AvgPool2D(pool_size=2, strides=2))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(120, activation='sigmoid'))\n",
        "  model.add(Dense(84, activation='sigmoid'))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkfpG9xG0npM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a006c78f-f729-465b-bbd1-f0af1acac6a7"
      },
      "source": [
        "model=lenet_model()\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 6)         156       \n",
            "_________________________________________________________________\n",
            "average_pooling2d (AveragePo (None, 14, 14, 6)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 10, 10, 16)        2416      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_1 (Average (None, 5, 5, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 120)               48120     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 84)                10164     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                850       \n",
            "=================================================================\n",
            "Total params: 61,706\n",
            "Trainable params: 61,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XheQst5hU8m8"
      },
      "source": [
        "AlexNet_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qtR-C-wzejn"
      },
      "source": [
        "def alexnet_model():\n",
        "  \n",
        "  np.random.seed(1000)\n",
        "  \n",
        "  #Instantiation\n",
        "  AlexNet = Sequential()\n",
        "  \n",
        "  #1st Convolutional Layer\n",
        "  AlexNet.add(Conv2D(filters=96, input_shape=(32,32,3), kernel_size=(11,11), strides=(4,4), padding='same'))\n",
        "  AlexNet.add(BatchNormalization())\n",
        "  AlexNet.add(Activation('relu'))\n",
        "  AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "  \n",
        "  #2nd Convolutional Layer\n",
        "  AlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\n",
        "  AlexNet.add(BatchNormalization())\n",
        "  AlexNet.add(Activation('relu'))\n",
        "  AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "  \n",
        "  #3rd Convolutional Layer\n",
        "  AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "  AlexNet.add(BatchNormalization())\n",
        "  AlexNet.add(Activation('relu'))\n",
        "  \n",
        "  #4th Convolutional Layer\n",
        "  AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "  AlexNet.add(BatchNormalization())\n",
        "  AlexNet.add(Activation('relu'))\n",
        "  \n",
        "  #5th Convolutional Layer\n",
        "  AlexNet.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "  AlexNet.add(BatchNormalization())\n",
        "  AlexNet.add(Activation('relu'))\n",
        "  AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "  \n",
        "  #Passing it to a Fully Connected layer\n",
        "  AlexNet.add(Flatten())\n",
        "  # 1st Fully Connected Layer\n",
        "  AlexNet.add(Dense(4096, input_shape=(32,32,3,)))\n",
        "  AlexNet.add(BatchNormalization())\n",
        "  AlexNet.add(Activation('relu'))\n",
        "  # Add Dropout to prevent overfitting\n",
        "  AlexNet.add(Dropout(0.4))\n",
        "  \n",
        "  #2nd Fully Connected Layer\n",
        "  AlexNet.add(Dense(4096))\n",
        "  AlexNet.add(BatchNormalization())\n",
        "  AlexNet.add(Activation('relu'))\n",
        "  #Add Dropout\n",
        "  AlexNet.add(Dropout(0.4))\n",
        "  \n",
        "  #3rd Fully Connected Layer\n",
        "  AlexNet.add(Dense(1000))\n",
        "  AlexNet.add(BatchNormalization())\n",
        "  AlexNet.add(Activation('relu'))\n",
        "  #Add Dropout\n",
        "  AlexNet.add(Dropout(0.4))\n",
        "  \n",
        "  #Output Layer\n",
        "  AlexNet.add(Dense(10))\n",
        "  AlexNet.add(BatchNormalization())\n",
        "  AlexNet.add(Activation('softmax'))\n",
        "  \n",
        "  return AlexNet\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZLErymE0sPp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b550788-84cd-4eb4-caaa-d819f6ced8f6"
      },
      "source": [
        "model2=alexnet_model()\n",
        "model2.summary()\n",
        "print(\"\\n\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 96)          34944     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 8, 8, 96)          384       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 8, 8, 96)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 4, 4, 96)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 4, 4, 256)         614656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 2, 2, 384)         885120    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 2, 2, 384)         1536      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 2, 2, 384)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 2, 2, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 2, 2, 384)         1536      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 2, 2, 384)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 2, 2, 256)         884992    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 2, 2, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                10010     \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 10)                40        \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 25,730,506\n",
            "Trainable params: 25,709,350\n",
            "Non-trainable params: 21,156\n",
            "_________________________________________________________________\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}